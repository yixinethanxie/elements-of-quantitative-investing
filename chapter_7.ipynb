{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9003acb5-d5ef-430f-8698-14dc502a0e92",
   "metadata": {},
   "source": [
    "# Chapter 7 - Statistial Factor Models\n",
    "\n",
    "## 7.1 Basics\n",
    "\n",
    "### 7.1.1 Best Low-Rank Approximation and PCA\n",
    "\n",
    "A factor model is $R = BF$, to decompose the returns $R$ into low-ranked factors $F$ via factor loadings $B$, we run SVD, $R=USV^T$. Sort the columns of $U$ and rows of $V$ based on the diagonal matrix $S$ in descending order, we can select the first $m$ components where $m<n$, such that\n",
    "\n",
    "$$R \\simeq U_mS_mV_m^T $$\n",
    "\n",
    "Assign\n",
    "\n",
    "$$B = U_m$$\n",
    "$$F = S_mV_m^T$$\n",
    "\n",
    "To formulate PCA as a eigenvalue decomposition (EVD) problem, we have\n",
    "\n",
    "$$ \\max w^T\\hat{\\Sigma}w$$\n",
    "$$\\text{s.t. } ||w|| \\leq 1$$\n",
    "\n",
    "Solve it with Langrangian\n",
    "\n",
    "\\begin{align}\n",
    "L & = -w^T\\hat{\\Sigma}w + \\lambda (w^Tw - 1) \\\\\n",
    "dL & = -2\\hat{\\Sigma}w + 2\\lambda w = 0 \\\\\n",
    "    \\hat{\\Sigma}w &= \\lambda w \\\\\n",
    "    \\lambda &= w^T\\hat{\\Sigma}w\n",
    "\\end{align}\n",
    "\n",
    "Since the goal is to maximize $w^T\\hat{\\Sigma}w$ and $\\lambda = w^T\\hat{\\Sigma}w$, and solution is the eignvector associated with the highest eignvalue. \n",
    "\n",
    "To formulate PCA as a SVD problem, we have \n",
    "\\begin{align}\n",
    "R &= USV^T \\\\\n",
    "\\hat{\\Sigma} &= \\frac{1}{T} RR^T \\\\\n",
    "            &= \\frac{1}{T} (USV^T)(VSU^T) \\\\\n",
    "            &= \\frac{1}{T} US^2U^T \\\\\n",
    "w^T\\hat{\\Sigma}w &= \\frac{1}{T} w^TUS^2U^Tw \\\\\n",
    "\\end{align}\n",
    "\n",
    "Set $U^Tw = v$, we have\n",
    "\\begin{align}\n",
    "\\text{max } & v^TS^2v \\\\\n",
    "\\text{s.t. } & v^Tv \\leq 1\n",
    "\\end{align}\n",
    "\n",
    "Since $S^2$ is a diagonal matrix sorted in descending order, the optimal solution is $v = (1,0,\\ldots,0)^T$, e.g. we want to select the first (largest) diagonal value.\n",
    "\n",
    "If the diagonal values (eigen values) in $S^2$ aren't unique, the solution $v$ isn't unique either, say we have $\\lambda_1 = \\lambda_2$:\n",
    "\n",
    "\\begin{align}\n",
    "\\lambda_1 &= v_1^TS^2v_1 \\\\\n",
    "\\lambda_1 &= v_1^2S_1^2 \\\\\n",
    "\\lambda_2 &= v_2^TS^2v_2 \\\\\n",
    "\\lambda_2 &= v_2^2S_2^2\n",
    "\\end{align}\n",
    "\n",
    "Then there is $\\lambda_3 = \\lambda_1 + \\lambda_2$ with eignvector $v_3 = (v_1, v_2, \\ldots,0)^T$ that\n",
    "\n",
    "\\begin{align}\n",
    "\\lambda_3 &= v_1^2S_1^2 + v_2^2S_2^2 = v_3^TS^2v_3\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "Finally, to solve for $m < n$ components in one go, we have\n",
    "\n",
    "\\begin{align}\n",
    "\\text{max } & trace(W^T\\hat{\\Sigma}W) \\\\\n",
    "\\text{s.t. } & W^TW = I_m \\\\\n",
    "W & \\in R^{n\\times m}\n",
    "\\end{align}\n",
    "\n",
    "Same as solving eignvectors one by one with each subsequent problem having an additional contraint that the new eigenvector being orthogonal to the previous ones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f02f5a5-e274-49d7-8ef8-e804e1ceacc5",
   "metadata": {},
   "source": [
    "### 7.1.2 MLE and PCA\n",
    "\n",
    "The idea is to start with a rotated factor model so that the factor covariance matrix is an identity matrix, which can be achieved following section 4.4.1 (identify factor covariance matrix). Assume constant and diagonal idio covariance matrix. \n",
    "\n",
    "$$ f \\sim N(0,I_m) $$\n",
    "$$ \\epsilon \\sim N(0, \\sigma^2 I_n) $$\n",
    "$$ \\Sigma_r = BB^T + \\sigma^2 I_n $$\n",
    "\n",
    "MLE on the factor covariance matrix becomes:\n",
    "\n",
    "$$ \\max -\\log|\\hat{\\Sigma}_r| - \\langle \\hat{\\Sigma}_r^{-1}, \\Sigma_r \\rangle $$\n",
    "$$ \\hat{\\Sigma}_r = \\hat{B}\\hat{B}^T + \\hat{\\sigma}^2I_n$$\n",
    "\n",
    "Where $\\Sigma_r$ is the empirical covariance matrix. The solution is:\n",
    "\n",
    "\\begin{align}\n",
    "    \\hat{B} & = U_m(S_m - \\hat{\\sigma}I_m)^{1/2} \\\\\n",
    "    \\hat{\\sigma}^2 & = \\bar{\\lambda}\n",
    "\\end{align}\n",
    "\n",
    "Where $\\bar{\\lambda}$ is the average of the last n-m eigenvalues. We can apply a transformation to make it more intuitive:\n",
    "\n",
    "\\begin{align}\n",
    "    \\hat{B} & = U_m \\\\\n",
    "    \\Sigma_f & = S_m - \\bar{\\lambda}I_m \\\\\n",
    "    \\Sigma_{\\epsilon} & = \\bar{\\lambda}I_n \n",
    "\\end{align}\n",
    "\n",
    "The transformation provides the insight: we shrink factor variance by the \"unselected\" factors and categorize those as idio returns/variance. \n",
    "\n",
    "Experiments show that:\n",
    "- shrinkage mentioned above help counters the upward bias of sample factor variance estimate.\n",
    "- however, the shrinkage tends to overcorrete and introduce downward bias. Therefore, the MLE approach is generally biased.\n",
    "\n",
    "\n",
    "### 7.1.3 Regressions via SVD\n",
    "\n",
    "Once we know the factor loadings $U_m$ and asset returns $R$, we can get the factor returns via regression and vice versa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89487d81-e5f9-402c-8be5-55d88ce5f6ad",
   "metadata": {},
   "source": [
    "## 7.2 Beyond Basics\n",
    "\n",
    "### Spiked Covariance Model\n",
    "\n",
    "For the empirical covariance matrix:\n",
    "$$\\tilde{\\Omega}_r = T^{-1}\\sum^T_{t=1}r_tr_t^T$$\n",
    "\n",
    "The matrix is spiked if there is an $m$ that $0<m<n$ and a positive constant $C$ such that as $T \\to \\infty$, the eigenvalues:\n",
    "\n",
    "$$\\lambda_i = \\lim_{T\\to\\infty}\\lambda_{T,i}\\begin{cases}\n",
    "= 1 \\text{    for all i > m} \\\\\n",
    "\\geq Cn \\text{    for all i } \\leq m\n",
    "\\end{cases}$$\n",
    "\n",
    "A spiked matrix has a subset of eigenvalues that scale with the size of the matrix, while the rest of the eignvalues is constant. In the context of factor model, as we add more assets into the universe, the variance between factor and idio returns become larger and larger, to a point that the idio variances are negligible thus \"diversified\" away.\n",
    "\n",
    "To see this, assume we have done the rotation and rescaling that both factor and idio covariance matrices are identiy matrix, and the covariance matrix is now: $BB^T+I_n$. Since the eignvalues of $BB^T$ and $B^TB$ are the same, we can write $B^TB = \\sum b_i^Tb_i$ where $b_i$ is ith row of $B$. We can then rewrite the $B^TB = n(1/n\\sum b_i^Tb_i) = nE(b_i^Tb)$. Let $\\mu_i$ be the eigvalues of the expectation, the eigenvalues of $B^TB$ are then $n\\mu_i$. The overall covariance matrix is now $n\\mu_i + 1$. As n increases the factor eignvalues increase while the idio eigenvalues stay constant.\n",
    "\n",
    "To illustrate and borrow points from section 9.3, the ith FMP is $w_i = B(B^TB)^{-1}e_i$. Plug into the covariance matrix. Factor covariance matrix:\n",
    "\n",
    "$$w_i^T(BB^T)w_i = e_i^{T}(B^TB)^{-1}B^T(BB^T)B(B^TB)^{-1}e_i=1$$\n",
    "\n",
    "Idio covariance matrix:\n",
    "\n",
    "\\begin{align}\n",
    "w_i^Tw_i &= e_i^T(B^TB)^{-1}B^TB(B^TB)^{-1}e_i \\\\ \n",
    "        &= e_i^T(B^TB)^{-1}e_i \\\\\n",
    "        &= e_i^TVS^{-2}V^Te_i \\\\\n",
    "        &\\leq \\lambda_m^{-1} e_i^TVV^Te_i \\\\\n",
    "        &= \\lambda_m^{-1} ||V^Te_i||^2 \\\\\n",
    "        &\\leq \\lambda_m^{-1} ||V^T||^2||e_i||^2 \\\\\n",
    "        &= \\lambda_m^{-1} ||V^T||^2 \\\\\n",
    "        &= \\lambda_m^{-1} \\\\\n",
    "        &\\leq 1/Cn\n",
    "\\end{align}\n",
    "Where $\\lambda_m$ is the mth largest eignvalue of $BB^T$ and $B^TB$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7349ae8-aa42-484c-bbac-b57d71c87245",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
