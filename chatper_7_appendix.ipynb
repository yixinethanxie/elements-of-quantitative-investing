{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50571af2-6e6f-4c3b-9f9d-48b17303b54d",
   "metadata": {},
   "source": [
    "# Chapter 7 Appendix\n",
    "\n",
    "## Exercises\n",
    "\n",
    "### 7.1\n",
    "Prove that a matrix A with shape (nxT) is of rank $m \\leq \\min \\{n, T\\}$ if and only if it can be decomposed into the product of two matrices B (nxm) and C (mxT) that are full rank.\n",
    "\n",
    "proof:\n",
    "\n",
    "Direction 1($\\Rightarrow$)\n",
    "\n",
    "Apply SVD on A: $A = USV^T$, since A has rank r, we can take the top r singular values and its corresponding columns in U an V, since the rest of the singular values are 0 and we can safely omit them. The matrix A now becomes $A = U_rS_rV_r^T$. Set $B=U_rS_r$ and $C=V_r^T$, we get the result $A=BC$.\n",
    "\n",
    "Direction 2($\\Leftarrow$)\n",
    "\n",
    "If $\\text{rank} (B) = \\text{rank} (C) = m$ then $\\text{rank} (A) = \\text{rank} (BC) = m$.\n",
    "\n",
    "### 7.2\n",
    "\n",
    "(7.7) solves for the first eigenvector (largest eigenvalue) and (7.10) solves for the second eigenvector (second largest eigenvalue). It is possible that a covariance matrix has repeated eigenvalues, and infinitely many eigenvectors, so I don't know how to prove the solution (eigenvector) uniqueness. However, the constraint being binding indicates that the lagrangian multiplier $\\lambda$ must be positive, which is also the eigenvalue. Again, since a covariance matrix must be PSD, there is at least one positive eigenvalue, so (7.7) must be binding, yet the second eigenvalue may be zero.\n",
    "\n",
    "### 7.3\n",
    "\n",
    "the objective can be translated as following, which is sum of the variances of the eigenportfolios.\n",
    "\n",
    "\\begin{align}\n",
    "\\text{trace }\\left(W^T\\hat{\\Sigma}W\\right) = \\sum_{i=1}^{m} w_i^T\\hat{\\Sigma}w_i\n",
    "\\end{align}\n",
    "\n",
    "since each eigenvector $w_i$ must corresponding to the max eigenvalue while being orthogonal to all preceding eigenvectors, the sum of eigenvalues are maximized.\n",
    "the constratraint can be translated as following, which means that each weight vector must be unit norm and orthogonal to each other.\n",
    "\n",
    "\\begin{align}\n",
    "W^TW &= I_m \\\\\n",
    "w_i^Tw_i &= 1 \\\\\n",
    "w_i^Tw_j &= 0 \\text{, where } i \\neq j \\\\\n",
    "\\end{align}\n",
    "\n",
    "since the weight constraint must be binding from the previous proof, and eigenvectors are all orthogonal to each other, the constraints match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd84f57f-552b-49cc-8d5b-bcdc78c08900",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6db0125-0456-45b3-aa1c-31d5b6d22c50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
